{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dataset\n",
    "from Datasets.GaussianSample import GaussianData\n",
    "\n",
    "#Model Related Imports\n",
    "from Models.CHLN import CHLN\n",
    "from torch.nn import CrossEntropyLoss, Sigmoid, ReLU, Softsign\n",
    "import torch.optim as optim \n",
    "\n",
    "#Import Training Environment\n",
    "from TrainingEnvironments.ContrastiveHebbianLearningTrainingEnvironment import CHLTrainingEnvironment\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant Model Parameters\n",
    "layer_shapes = [10, 10, 10, 1028]\n",
    "\n",
    "#Constant Environment Parameters\n",
    "epochs = 50\n",
    "batches = 100\n",
    "batchsize = 10\n",
    "\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can only display two dimensions.\n"
     ]
    }
   ],
   "source": [
    "data = GaussianData(layer_shapes[-1], layer_shapes[0])\n",
    "data.showData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Shell\n",
    "\n",
    "# Variable Model Parameters\n",
    "# Creation of Model and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1028 is different from 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Creation and Running of Training Environment\u001b[39;00m\n\u001b[32m     13\u001b[39m Experiment1 = CHLTrainingEnvironment(data, model, criterion, opt_param, epochs, batches, batchsize)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mExperiment1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m#loss_data, accuracy_data, mean_activation_data, std_activation_data = Experiment1.trainModel()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Conka\\Documents\\Code\\Project1\\TrainingEnvironments\\ContrastiveHebbianLearningTrainingEnvironment.py:38\u001b[39m, in \u001b[36mCHLTrainingEnvironment.trainModel\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     34\u001b[39m         inputs, labels = \u001b[38;5;28mself\u001b[39m.Dataset.\u001b[34m__getitem__\u001b[39m(indices)\n\u001b[32m     37\u001b[39m         free_x = \u001b[38;5;28mself\u001b[39m.Model.freePhase(inputs)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         clamped_x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclampedPhase\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m         \u001b[38;5;28mself\u001b[39m.Model.update(\u001b[38;5;28mself\u001b[39m, free_x, clamped_x)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSuccessful Pass Through\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Conka\\Documents\\Code\\Project1\\Models\\CHLN.py:37\u001b[39m, in \u001b[36mCHLN.clampedPhase\u001b[39m\u001b[34m(self, x0, y, T)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_layers-\u001b[32m1\u001b[39m):\n\u001b[32m     36\u001b[39m     d_x = x[k-\u001b[32m1\u001b[39m] @ \u001b[38;5;28mself\u001b[39m.W[k-\u001b[32m1\u001b[39m] + \u001b[38;5;28mself\u001b[39m.b[k-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     d_x += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\n\u001b[32m     38\u001b[39m     d_x = \u001b[38;5;28mself\u001b[39m.sigmoid(d_x)\n\u001b[32m     39\u001b[39m     x[k] += -x[k] + d_x\n",
      "\u001b[31mValueError\u001b[39m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1028 is different from 10)"
     ]
    }
   ],
   "source": [
    "# Variable Model Parameters\n",
    "activation_function = Sigmoid\n",
    "\n",
    "#Creation of Model and Optimizer\n",
    "model = CHLN(layer_shapes, activation_function)\n",
    "\n",
    "#Optimizer defined in CHL training environment\n",
    "gamma = 0.1\n",
    "lr = 0.1\n",
    "opt_param = [gamma, lr]\n",
    "\n",
    "# Creation and Running of Training Environment\n",
    "Experiment1 = CHLTrainingEnvironment(data, model, criterion, opt_param, epochs, batches, batchsize)\n",
    "Experiment1.trainModel()\n",
    "\n",
    "#loss_data, accuracy_data, mean_activation_data, std_activation_data = Experiment1.trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss and accuracy curves\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(loss_data, label='Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss Curve')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(accuracy_data, label='Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Accuracy Curve')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the mean values with error bars representing the standard deviation\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for layer in range(len(hidden_shapes)):\n",
    "#     plt.errorbar(range(epochs), mean_activation_data[layer], yerr=std_activation_data[0], fmt='-o', capsize=5, capthick=1)\n",
    "\n",
    "\n",
    "# # Labeling the plot\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Mean Value')\n",
    "# plt.title('Mean Values Across Epochs with Standard Deviation')\n",
    "# plt.legend(['Layer1', 'Layer2', 'Layer3', 'Layer4'])\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Display the plot\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
