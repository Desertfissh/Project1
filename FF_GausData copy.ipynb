{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss, Sigmoid, ReLU, Softsign\n",
    "from TrainingEnvironments.FeedForwardTrainingEnvironment import FeedForwardTrainingEnvironment\n",
    "from Datasets.GaussianSample import GaussianData\n",
    "\n",
    "from Models.MLP import MLP\n",
    "import torch.optim as optim \n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant Model Parameters\n",
    "input_shape = 2\n",
    "output_shape = 2\n",
    "\n",
    "#Constant Environment Parameters\n",
    "epochs = 250\n",
    "batches = 200\n",
    "batchsize = 10\n",
    "\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = GaussianData(output_shape, input_shape)\n",
    "#data.showData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Shell\n",
    "\n",
    "# Variable Model Parameters\n",
    "# Creation of Model and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trial', 'Depth', 'Width', 'Epoch', 'Accuracy', 'Loss', 'Layer 1 Mean Activations', 'Layer 2 Mean Activations', 'Layer 1 STD Activations', 'Layer 2 STD Activations', 'Layer 1 Mean Gradient', 'Layer 2 Mean Gradient', 'Layer 1 STD Gradient', 'Layer 2 STD Gradient']\n",
      "[3, 3]\n"
     ]
    }
   ],
   "source": [
    "# Variable Model Parameters\n",
    "trials = 10\n",
    "hidden_shapes_list = [\n",
    "    [1],\n",
    "    [2],\n",
    "    [3],\n",
    "    [4],\n",
    "    [1,1],\n",
    "    [2,2],\n",
    "    [3,3],\n",
    "    [4,4],\n",
    "    [1,1,1],\n",
    "    [2,2,2],\n",
    "    [3,3,3],\n",
    "    [4,4,4]\n",
    "    \n",
    "    ]\n",
    "activation_function = ReLU\n",
    "\n",
    "data_columns = [\"Trial\", \"Depth\", \"Width\", \"Epoch\", \"Accuracy\", \"Loss\"]\n",
    "\n",
    "\n",
    "for trial in range(trials):\n",
    "    data = GaussianData(output_shape, input_shape)\n",
    "\n",
    "    for hidden_shapes in hidden_shapes_list:\n",
    "        \n",
    "        current_data_columns = data_columns + [f'Layer {i+1} Mean Activations' for i in range(len(hidden_shapes))] + [f'Layer {i+1} STD Activations' for i in range(len(hidden_shapes))] + [f'Layer {i+1} Mean Gradient' for i in range(len(hidden_shapes))] + [f'Layer {i+1} STD Gradient' for i in range(len(hidden_shapes))]\n",
    "        print(current_data_columns)\n",
    "\n",
    "        #Creation of Model and Optimizer\n",
    "        model = MLP(input_shape, hidden_shapes, output_shape, activation_function)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "        # Creation and Running of Training Environment\n",
    "        print(hidden_shapes)\n",
    "        Experiment1 = FeedForwardTrainingEnvironment(data, model, criterion, optimizer, epochs, batches, batchsize)\n",
    "        loss_data, accuracy_data, mean_activation_data, std_activation_data, mean_gradient_data, std_gradient_data = Experiment1.trainModel()\n",
    "\n",
    "        pd.DataFrame(torch.cat((\n",
    "                        torch.stack((\n",
    "                            trial*torch.ones(epochs),\n",
    "                            len(hidden_shapes)*torch.ones(epochs),\n",
    "                            hidden_shapes[0]*torch.ones(epochs),\n",
    "                            torch.tensor(range(epochs)),\n",
    "                            torch.tensor(accuracy_data),\n",
    "                            torch.tensor(loss_data),\n",
    "                        ), dim=1),                         \n",
    "                        torch.tensor(mean_activation_data).T,\n",
    "                        torch.tensor(std_activation_data).T,\n",
    "                        torch.tensor(mean_gradient_data).T,\n",
    "                        torch.tensor(std_gradient_data).T\n",
    "                    ), dim=1),\n",
    "                    columns=current_data_columns).to_csv(f\"./CollectedData/ReLU/trial{str(trial+1)}_depth{len(hidden_shapes)}_width{hidden_shapes[0]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 250]) torch.Size([2, 250])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(mean_gradient_data).shape, torch.tensor(std_gradient_data).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
